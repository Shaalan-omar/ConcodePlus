<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Code Generation / Documentation model based on CodeT5</title>

  <!-- Bootstrap core CSS -->
  <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

</head>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark static-top">
    <div class="container">
      <a class="navbar-brand" href="../home.html">Practical Machine Deep Learning</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item active">
            <a class="nav-link" href="../home.html">Home
              <span class="sr-only">(current)</span>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../about.html">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../contact.html">Contact</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Content -->
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center">
        <h1 class="mt-5">Code Generation / Documentation model based on CodeT5</h1>
        <ul class="list-unstyled">
          <li>Omar Shaalan 900193887</li>
          <li>Kyrollos Zakarya 900203309</li>
        </ul>
      </div>
    </div>


    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5"></h2>
		
        <h1>
          Problem statement
           </h1>
           <p>
            Auto code generation is an increasingly popular approach to software development that offers significant benefits in terms of speed, efficiency, and accuracy. However, the resulting code can be difficult to understand and modify, particularly when it lacks sufficient documentation or comments. This problem can lead to errors, delays, and additional costs in software development projects. Therefore, there is a critical need for auto code generation tools that can automatically generate commented code, helping developers to understand and modify the code more easily and efficiently.
       <br/> <!-- Empty Line before the image -->
         <div class="img-container" align="center"> <!-- Block parent element -->
             <img src="resources/images/Screen Shot 2023-05-14 at 12.21.35 PM.png" class="img-fluid text-center">
         </div>
         
         <br/> <!-- Empty Line after the image -->
        <p>
          As you can see comments make a great difference in code readability and understandability.
        </p>
      </div>
    </div>

    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Dataset</h2>

        <h3 class="mt-5">Initial Dataset</h3>
        <p>
          Initially, our intention was to utilize the Concode dataset, which was used for CodeT5 finetuning in the code generation task. Our aim was to create ConcodePlus task, a commented code generation task. However, we faced limitations as the Concode dataset consists of 100,000 pairs of natural language prompts and code. 
    </p>
    <br/> <!-- Empty Line before the image -->
    <div class="img-container" align="center"> <!-- Block parent element -->
        <img src="resources/images/concode.png" class="img-fluid text-center">
    </div>
    <br/> <!-- Empty Line after the image -->
    <h3 class="mt-5">Modified Dataset</h3>
    <p>
      We tried numerous approaches to obtain a suitable dataset but we settled on adjusting and modifying CodeSearchNet dataset to obtain a dataset consists of pairs of natural language prompts and commented code. We called PyPlus, as this dataset consists of more than 250,000 pair of commented Python codes with their prompts. 
</p>
<br/> <!-- Empty Line before the image -->
<div class="img-container" align="center"> <!-- Block parent element -->
    <img src="resources/images/dataset.png" class="img-fluid text-center">
</div>
	<p>
    As illustrated, the "docstring" represent the code prompt and it is the input for our model, and the "code" cells contains detailed comments.
  </p>
      </div>
    </div>

    <div class="row">
      <br class="col-lg-12 text-left">
        <h2 class="mt-5">Input/Output Examples</h2>
            For illustrative purpose, we will use tha same prompt (input) with the pretrained model, finetuned Concode, finetuned ConcodePlus.
            <br></br>
          <h4>
			      Prompt: 
          </h4>
          <h5>
            pretrained CodeT5
          </h5>
      	  <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/output_real.png" class="img-fluid text-center">
    	</div>
      <!-- <p class = "center">
        Feel the difference?
     </p> -->
     <br>
    </br>
  
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>

  
    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">State of the art (PARSEL)</h2>

        <p>
          Parsel, an OpenAI deep learning project, has been a leading force in the field of code generation and code summarization tasks. It utilizes the powerful GPT (Generative Pre-trained Transformer) architecture. The version discussed in the tables and graphs incorporates 1.5 billion parameters and it is the large version of Parsel. Unfortunately, the weights of the Parsel model were not readily available to us, and training the model ourselves was not feasible due to the immense computational power required.
		</p>

	  <br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/parsel_code_sum.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->

    <br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/Parsel_code_gen.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/Screeneeee.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>



    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Orignial Model from Literature.</h2>

        <p>
			The model, CodeT5, has 3 main versions. The small, base, and large. The small has 60 million parameters, the large has 770 million parameters and the base version is 220 million parameters.
      Working with the small version due to the limitations on Google Colab, which makes it very hard to work with versions that had larger size from the parameters prespective. However, working with the small version ended up to reaching bad results 
      as explained in our previous presentations. However, working with PyPlus, the new dataset, made it easier to work with the small version.
		</p>

		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/codet5_arch.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      <table>
        <thead>
        <tr>
        <th>--task</th>
        <th>--sub_task</th>
        <th>Description</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td>summarize</td>
        <td>ruby/javascript/go/python/java/php</td>
        <td>code summarization task on <a href="https://arxiv.org/abs/1909.09436" rel="nofollow">CodeSearchNet</a> data with six PLs</td>
        </tr>
        <tr>
        <td>concode</td>
        <td>none</td>
        <td>text-to-code generation on <a href="https://aclanthology.org/D18-1192.pdf" rel="nofollow">Concode</a> data</td>
        </tr>
        <tr>
        <td>translate</td>
        <td>java-cs/cs-java</td>
        <td>code-to-code translation between <a href="https://arxiv.org/pdf/2102.04664.pdf" rel="nofollow">Java and C#</a></td>
        </tr>
        <tr>
        <td>refine</td>
        <td>small/medium</td>
        <td>code refinement on <a href="https://arxiv.org/pdf/1812.08693.pdf" rel="nofollow">code repair data</a> with small/medium functions</td>
        </tr>
        <tr>
        <td>defect</td>
        <td>none</td>
        <td>code defect detection in <a href="https://proceedings.neurips.cc/paper/2019/file/49265d2447bc3bbfe9e76306ce40a31f-Paper.pdf" rel="nofollow">C/C++ data</a></td>
        </tr>
        <tr>
        <td>clone</td>
        <td>none</td>
        <td>code clone detection in <a href="https://arxiv.org/pdf/2002.08653.pdf" rel="nofollow">Java data</a></td>
        </tr>
        </tbody>
      </table>
      </div>
    </div>


    <div class = "row">
        <div class="col-lg-12 text-left" >
            <h2 class="mt-5" >Updates </h2>

              <h5 class="mt-5">Update #1: Commented Code generation</h5>
              <p>
                We have reached the desired output by generating commented code that serves the problem statment's goals. The comments are meaningful and cosidered correct from the description of the code prespective.
                Below are the steps of reaching such a goal.
              </p>
              <div class="img-container" align="center"> <!-- Block parent element -->
                <img src="resources/images/workflow.png" class="img-fluid text-center">
            </div>
            <p>
              We first had to configure the new task. To do this we had to change the config.py file, we added code for the ConcodePlus
              task allowing it to be defined in our model. We then needed to creat a new reading function that reads the dataset that 
              reads PyPlus dataset. For such a task we added a new reading function to the Utils.py file. What was left was adding 
              the data path. We did this by adding the datapath to _Utils.py
            </p>
           
        </div>
    </div>


    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Recommended Future Updates</h2>


		<h5 class="mt-5">Update #1: Adding Reinforcement Learning</h5>
		<p>
			Give rewards when the generated documentation along with the code is correct and add negative rewards when the generation is not good.
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/reinforcement.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->

      	<p>
			Hyperparameter tune the model. Base on one of the very famous concepts we took in our class is the concept of trial and error. Please feel free to try
      several times to change and tune the hyperprameters in order to reach better results. Feel free to share your outcomes with us.
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/copyHyper.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>


    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Results</h2>

        <p>
			Please find below our results obtained after adding our task, ConcodePlus, and the plots too.
		</p>

		<br/> <!-- Empty Line before the image -->
    	<h3 class="mt-5">It is obvious that there is something wrong with calculations of the metrics of concodePlus 
      since the blue score definitely does not reflect the model performance. This can be due to the fact that we added
       a new task to the model without taking into account the synchronization required to measure these metrices for the 
      new task specifically </h3>
      <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/metrics_obtained.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/dev_metric.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/dev2_metric.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/metric3.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>


    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Technical report</h2>


	 	<ul>
		  <li>Programming framework</li>
      anaconda virtual environments, We used pytorch.
      it needs these dependencies to deploy our model smoothly:
        Pytorch 1.7.1
        tensorboard 2.4.1
        transformers 4.6.1
        tree-sitter 0.2.2
        conda 4.12.0
		  <li>Training hardware i.e. colab or azure or anything else</li>
      we worked on: CPU: Intel® Xeon(R) W-2145 CPU @ 3.70GHz × 16 with RAM of 31GB
      and with Graphics card: NVIDIA Corporation GP104GL [Quadro P5000]
		  <li>Training time</li>
      12.5 hours for 10 Epochs
		  <li>Number of epochs</li>
      10
      <li>Time per epoch</li>
      <p>Here are the starting and ending times, along with the duration, for each epoch:</p>
      <ol>
        <li>First Epoch:
          <ul>
            <li>Starting: 04/19/2023 16:28:09</li>
            <li>Ending: 04/19/2023 17:42:07</li>
            <li>Duration: 1 hour, 13 minutes, 58 seconds</li>
          </ul>
        </li>
        <li>Second Epoch:
          <ul>
            <li>Starting: 04/19/2023 17:42:07</li>
            <li>Ending: 04/19/2023 18:55:48</li>
            <li>Duration: 1 hour, 13 minutes, 41 seconds</li>
          </ul>
        </li>
        <li>Third Epoch:
          <ul>
            <li>Starting: 04/19/2023 18:55:48</li>
            <li>Ending: 04/19/2023 20:09:27</li>
            <li>Duration: 1 hour, 13 minutes, 39 seconds</li>
          </ul>
        </li>
        <li>Fourth Epoch:
          <ul>
            <li>Starting: 04/19/2023 20:09:27</li>
            <li>Ending: 04/19/2023 21:23:26</li>
            <li>Duration: 1 hour, 13 minutes, 59 seconds</li>
          </ul>
        </li>
        <li>Fifth Epoch:
          <ul>
            <li>Starting: 04/19/2023 21:23:26</li>
            <li>Ending: 04/19/2023 22:37:48</li>
            <li>Duration: 1 hour, 14 minutes, 22 seconds</li>
          </ul>
        </li>
        <li>Sixth Epoch:
          <ul>
            <li>Starting: 04/19/2023 22:37:48</li>
            <li>Ending: 04/19/2023 23:52:03</li>
            <li>Duration: 1 hour, 14 minutes, 15 seconds</li>
          </ul>
        </li>
        <li>Seventh Epoch:
          <ul>
            <li>Starting: 04/19/2023 23:52:03</li>
            <li>Ending: 04/20/2023 01:05:50</li>
            <li>Duration: 1 hour, 13 minutes, 47 seconds</li>
          </ul>
        </li>
      </ol>
	    <div class="img-container" align="center"> <!-- Block parent element -->
        <img src="resources/images/training time.png" class="img-fluid text-center">
    </div>      
    <p>You can find the details of this training in concodePlus04.txt.</p>
		  <li>Any other important detail or difficulties</li>
      ran out of GPUs, there are more variations of Code-T5: base (220 Million parameter) and large (). but we couldn't use either of them because of computational power required. We, instead, used code-T5 small with only 60 million parameter.
		</ul> 
      </div>
    </div>

	<div class="row">
	  <div class="col-lg-12 text-left">
	    <h2 class="mt-5">Conclusion</h2>

	    <p>
        In conclusion, we have successfully achieved our goal by incorporating the ConcodePlus task into CodeT5 and creating the PyPlus dataset. The output provided above clearly demonstrates that our model now can generate meaningful documentation along with code. While we have achieved promising results, there are still areas that require further improvement. One potential area for enhancement is the addition of reinforcement learning to ConcodePlus.</p>
        <p> 
          During our project, we discovered the incredible power of transformers in deep learning. It was fascinating to see how these models effectively capture complex relationships and dependencies in both text and code. Furthermore, We were surprised by how similar text generation models are similar to code generation model as both of them relies on Large-language models but with more specialized training datasets in case of code generation that's why we are proud of the dataset we tailored for our model. This project was a wholesome learning experience that proved to be more challenging, which further motivated us to solve our problem and apply all we learnt throughout the course.
		</p>

	  </div>
	</div>

	<div class="row">
	  <div class="col-lg-12 text-left">
	    <h2 class="mt-5">References</h2>

	    <p>
	    	List all references here, the following are only examples
	    </p>

		<ol>
		  <li><a href="https://arxiv.org/pdf/2212.10561v2.pdf">Parsel Paper</a></li>
      <li><a href="https://microsoft.github.io/CodeXGLUE/">Parsel Code Summarization Table</a></li>
      <li><a href="https://microsoft.github.io/CodeXGLUE/">Parsel Code Generation Table</a></li>
		  <li><a href="https://arxiv.org/pdf/2109.00859v1.pdf">CodeT5 Paper</a></li>
		  <li><a href="https://medium.com/analytics-vidhya/t5-a-detailed-explanation-a0ac9bc53e51">CodeT5 Architecture Paper</a></li>
      <li><a href="https://github.com/salesforce/CodeT5">CodeT5 github Repository</a></li>
      <li><a href="https://huggingface.co/datasets/semeru/Text-Code-concode-Java">concode dataset</a></li>  
		  <li><a href="https://huggingface.co/datasets/code_search_net">CodeSearchNet dataset</a></li>
		</ol> 
	  </div>
	</div>

  </div>



  <!-- Bootstrap core JavaScript -->
  <script src="../vendor/jquery/jquery.slim.min.js"></script>
  <script src="../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</body>

</html>
